{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Power Analysis\n",
    "\n",
    "Depends on 4 variables:\n",
    "\n",
    "1. Effect size\n",
    "2. Significance level\n",
    "3. Power\n",
    "4. Sample size\n",
    "\n",
    "It consists of calculating one of them when the other three are known.\n",
    "This allows us to make statements about a sample size needed to detect an effect of a particular size and power with a given significance level.\n",
    "Conversely, we can use effect size, significance level, and sample size to calculate power, which tells us probability of a true positive, or of detecting an effect when it is in fact present."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from sample_size import TTestInd_sampleSize \n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this example, I will generate some fake data to be used for an independent-samples t-test. I will then run my sampleSize function (based on statsmodels) on it to determine optimal size for detecting the effect when it is present with given probability (power). Then, I will simulate a bunch of t-tests on data sampled from the same distribution with given sample size, and see how frequently we reject the null."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "# Fake data being drawn for two groups from two different gaussian distributions\n",
    "group1 = np.random.normal(10, 3, 50)\n",
    "group2 = np.random.normal(15, 3, 50)\n",
    "print(f'Group 1:\\n {group1}')\n",
    "print(f'Group 2:\\n {group2}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Group 1:\n",
      " [12.11691372 10.36894347 13.43720668 11.8866219  10.82192313  7.12392969\n",
      "  2.50964502 15.63633562  7.54383709 10.49838412  8.83401507  6.29253542\n",
      "  9.86078013 11.84799924 10.05574408  5.64204932 17.64512766  6.59261195\n",
      " 10.38271681  8.50807759 12.632553    6.9306526   6.65450317 11.07522337\n",
      " 14.86591563  8.59463654  5.18102537  8.57500053 17.3062279  10.48180088\n",
      "  9.59907445 10.25349628  9.73901364  6.90517474 10.22368715  9.69305301\n",
      " 12.09257413  8.60951899 10.32700848  8.23204587  5.33635271 11.16373777\n",
      "  9.14016431 11.28165625 12.2076035   7.7654185  11.00169739  8.15101644\n",
      "  8.90852985  8.55263671]\n",
      "Group 2:\n",
      " [14.69705427 22.09243121 22.24248907 11.39464979 15.83295736  9.49490043\n",
      " 17.22659644 15.84380874 11.79632582 10.53947189 16.01018034 11.13548514\n",
      "  9.50383527 22.21537013 11.48370646 14.24049975 15.67871062 15.00783001\n",
      "  9.70397104 12.15835552 14.25643688 14.7708116  14.25792219 13.72236548\n",
      " 21.58372642 18.19333862 12.614468   16.78158282 13.11331245 13.45719532\n",
      " 18.58249656 17.15566025 11.67325936 16.19021459 20.476382   14.79687656\n",
      " 15.98543297 16.37515845 19.17608582 16.85320948 15.83035468 22.69957873\n",
      " 16.84097282 16.41087299 12.71350271 16.29654051 13.75244701 14.82935335\n",
      " 13.38723624 15.66413168]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# Calculating sample size for t-test\n",
    "sample_size = TTestInd_sampleSize(\n",
    "    group1, \n",
    "    group2,\n",
    "    power=0.95,\n",
    "    alpha=0.05\n",
    ")\n",
    "print(f'Desired sample size for each group is: {sample_size}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Desired sample size for each group is: 10\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# Little utility function that I wrote to generate fake data on demand.\n",
    "def gen_samples():\n",
    "    global sample_size\n",
    "    sample1 = np.random.normal(10, 3, sample_size)\n",
    "    sample2 = np.random.normal(15, 3, sample_size)\n",
    "    return sample1, sample2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "\n",
    "# simulating a 1000 t-tests\n",
    "simulated_tests = [ttest_ind(*gen_samples()) for _ in range(1000)]\n",
    "# pulling p-values out of these t-tests\n",
    "pvalues = [res[1] for res in simulated_tests]\n",
    "# counting number of times we were able to detect an effect\n",
    "numreject = len(list(filter(lambda p: p < 0.05, pvalues)))\n",
    "# inferring number of times that we failed to detect an effect\n",
    "numfail = len(pvalues) - numreject\n",
    "print(f'Rejected: {numreject}\\nFailed: {numfail}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Rejected: 951\n",
      "Failed: 49\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "__NOTE: keep in mind, the analysis you reproduce will not have exact same number, but it should be close.__\n",
    "\n",
    "So, with our suggested sample size for each group, we:\n",
    "\n",
    "    Successfully rejected: 96.2% of time\n",
    "    Failed to reject: 3.8% of time\n",
    "\n",
    "This seems in line with the power that we set on the sample size calculation function given the following:\n",
    "\n",
    "1. Power represents the probability of a true positive\n",
    "2. We know that our sample has 100% true positives because we explicitly samples from two different distributions.\n",
    "3. We set our power to 0.95\n",
    "4. 96.2% of true positives were successfully detected\n",
    "\n",
    "So with 1000 t-tests ran on data samples from different distributions, we were able to successfully detect the effect approximately 95% of the time, which is what we set ourselves up for when setting the power to 0.95. Therefore, it seems that this method of determining preferred sample sizes for statistical tests is legit."
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('env': venv)"
  },
  "interpreter": {
   "hash": "ef6c6be7aab2af50209f4f7507feea8c1aa98544827ac1115d521d1fcfea3e63"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}